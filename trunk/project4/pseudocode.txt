queue: doubly-linked list with sentinel
cache: doubly-linked list with sentinel and associated hash table
prefetch: doubly-linked list with sentinel

cache hash table collision lists are doubly linked with trailing NULL at head and tail, hashes link to head



List operations:

LIST-ADD(L, x): Adds element x to linked list L

LIST-REMOVE(L, *x): Given an element x in linked list L, removes the element from the list without freeing it

LIST-SHIFT(L): Removes the element at the head of linked list L and returns a pointer to it




Hash operations:

HASHED-LIST-ADD(H, x): Adds element x (with key x.filename) to list H and its associated hash table

HASHED-LIST-SHIFT(H): Removes the element at the head of list H from the list and its associated hash table

HASHED-LIST-SEARCH(H, key): Returns the element in list H with hash key 'key'



init_lists():




Operations on queue:

addRequest(fd, fn): Adds new request with file descriptor fd and filename fn to the end of the request queue
   size = fn.filesize
   make a new request 'req' := (fd, fn, size)
   LIST-ADD(queue, req)

fetchRequest(): Removes and returns the element at the front of the request queue
   return LIST-SHIFT(queue)

fetchSmallRequest(): Removes and returns the element in the request queue with the smallest file size
   small = NULL
   smallsize = inf
   for each request 'req' in queue
      if req.filesize < smallsize
         small = req
         smallsize = req.filesize
   LIST-REMOVE(queue, small)
   return small




Operations on cache:

addEntry(fn, data): Adds new cache entry with filename fn and file data data to the end of the cache list and hashes it
   make a new entry 'ent' := (fn, data)
   if cache is full
      HASHED-LIST-SHIFT(cache)
   HASHED-LIST-ADD(cache, ent)

search(fn): Returns a copy of the cache entry matching filename fn, or null if no such entry exists in the cache
   make new cache entry 'ent'
   ent = HASHED-LIST-SEARCH(cache, fn)
   return ent





Operations on both the queue and the cache:

fetchCachedRequest(): Removes and returns the first element in the request queue that is cached, with its cache entry
   for each request 'req' in queue
      ent = cache.search( req.filename )
      if ent is not null
         LIST-REMOVE(queue, req)
         return (req, ent)
   return (queue.fetchRequest(), null)





Operations on prefetch:

addRequest(req)
   LIST-ADD(prefetch, req)

fetchRequest()
   return LIST-SHIFT(prefetch)






Operations used by the worker threads:

processRequest(req, ent):
   if ent is null
      make new data = req.filename.filedata
      ent = cache.addEntry(req.filename, data)
   determine content type of data
   use return_result or return_error appropriately






dispatch:
   make integer fd
   make string filename of size 1024
   make integer filesize
   while fd = accept_connection() is nonnegative
      if get_request(fd, &filename) is 0
         filesize = filename.filesize
         lock queue mutex
         check if queue is full
            if full, wait on queue put condition variable
         make new request req = (fd, filename, filesize)
         queue.putRequest(req)
         signal queue get condition variable
         unlock queue mutex


*fetchRequest set appropriately according to mode

Worker:
   while global_exit is false
      lock queue mutex
      if queue is empty
         wait on queue get condition variable
      lock cache mutex
      (req, ent) = queue.*getRequest()
      signal queue put condition variable
      unlock queue mutex
      processRequest(req, ent)
      unlock cache mutex
      lock log mutex
      log request
      unlock log mutex
      if prefetch not full
         lock prefetch mutex
         prefetch.addRequest(req)
         signal prefetch get condition variable
         unlock prefetch mutex
   while request queue not empty
      lock queue mutex
      lock cache mutex
      (req, ent) = queue.*getRequest() // no signal to queue put since queue is being emptied
      unlock queue mutex
      processRequest(req, ent)
      unlock cache mutex
      lock log mutex
      log request
      unlock log mutex
      if prefetch not full
         lock prefetch mutex
         prefetch.addRequest(req)
         signal prefetch get condition variable
         unlock prefetch mutex

prefetch:
   make new string guessed_filename
   while global_exit is false
      lock prefetch mutex
      if prefetch is empty
         wait on prefetch condition variable
      guessed_filename = guess_next( prefetch.getRequest() )
      unlock prefetch mutex
      if guess_next was successful
         make new data = guessed_filename.filedata
         lock cache mutex
         cache.putEntry(guessed_filename, data)
         unlock cache mutex


